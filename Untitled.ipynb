{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-119880bc84bc>, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-119880bc84bc>\"\u001b[1;36m, line \u001b[1;32m61\u001b[0m\n\u001b[1;33m    print \"Clustering score for k=%(k)d is %(score)f\" % {\"k\": k, \"score\": result[2]}\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# dataset: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Path for spark source folder\n",
    "os.environ['SPARK_HOME']=\"/path/to/spark\"\n",
    "\n",
    "# Append pyspark  to Python Path\n",
    "sys.path.append(\"/path/to/spark/python\")\n",
    "\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.mllib.clustering import KMeans\n",
    "    from pyspark.mllib.feature import StandardScaler\n",
    "    print (\"Successfully imported Spark Modules\")\n",
    "except ImportError as e:\n",
    "    print (\"Can not import Spark Modules\", e)\n",
    "    sys.exit(1)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "def parse_interaction(line):\n",
    "    \"\"\"\n",
    "    Parses a network data interaction.\n",
    "    \"\"\"\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = [line_split[0]]+line_split[4:-1]\n",
    "    return (line_split[-1], array([float(x) for x in clean_line_split]))\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the euclidean distance between two numeric RDDs\n",
    "    \"\"\"\n",
    "    return sqrt(\n",
    "        a.zip(b)\n",
    "        .map(lambda x: (x[0]-x[1]))\n",
    "        .map(lambda x: x*x)\n",
    "        .reduce(lambda a,b: a+b)\n",
    "        )\n",
    "\n",
    "\n",
    "def dist_to_centroid(datum, clusters):\n",
    "    \"\"\"\n",
    "    Determines the distance of a point to its cluster centroid\n",
    "    \"\"\"\n",
    "    cluster = clusters.predict(datum)\n",
    "    centroid = clusters.centers[cluster]\n",
    "    return sqrt(sum([x**2 for x in (centroid - datum)]))\n",
    "\n",
    "\n",
    "def clustering_score(data, k):\n",
    "    clusters = KMeans.train(data, k, maxIterations=10, runs=5, initializationMode=\"random\")\n",
    "    result = (k, clusters, data.map(lambda datum: dist_to_centroid(datum, clusters)).mean())\n",
    "    print \"Clustering score for k=%(k)d is %(score)f\" % {\"k\": k, \"score\": result[2]}\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if (len(sys.argv) != 3):\n",
    "        print \"Usage: /path/to/spark/bin/spark-submit --driver-memory 2g \" + \\\n",
    "          \"KDDCup99.py max_k kddcup.data.file\"\n",
    "        sys.exit(1)\n",
    "\n",
    "    # set up environment\n",
    "    max_k = int(sys.argv[1])\n",
    "    data_file = sys.argv[2]\n",
    "    conf = SparkConf().setAppName(\"KDDCup99\") \\\n",
    "      #.set(\"spark.executor.memory\", \"2g\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "\n",
    "    # load raw data\n",
    "    print \"Loading RAW data...\"\n",
    "    raw_data = sc.textFile(data_file)\n",
    "\n",
    "    # count by all different labels and print them decreasingly\n",
    "    print \"Counting all different labels\"\n",
    "    labels = raw_data.map(lambda line: line.strip().split(\",\")[-1])\n",
    "    label_counts = labels.countByValue()\n",
    "    sorted_labels = OrderedDict(sorted(label_counts.items(), key=lambda t: t[1], reverse=True))\n",
    "    for label, count in sorted_labels.items():\n",
    "        print label, count\n",
    "\n",
    "    # Prepare data for clustering input\n",
    "    # the data contains non-numeric features, we want to exclude them since\n",
    "    # k-means works with numeric features. These are the first three and the last\n",
    "    # column in each data row\n",
    "    print \"Parsing dataset...\"\n",
    "    parsed_data = raw_data.map(parse_interaction)\n",
    "    parsed_data_values = parsed_data.values().cache()\n",
    "\n",
    "    # Standardize data\n",
    "    print \"Standardizing data...\"\n",
    "    standardizer = StandardScaler(True, True)\n",
    "    standardizer_model = standardizer.fit(parsed_data_values)\n",
    "    standardized_data_values = standardizer_model.transform(parsed_data_values)\n",
    "\n",
    "    # Evaluate values of k from 5 to 40\n",
    "    print \"Calculating total in within cluster distance for different k values (10 to %(max_k)d):\" % {\"max_k\": max_k}\n",
    "    scores = map(lambda k: clustering_score(standardized_data_values, k), range(10,max_k+1,10))\n",
    "\n",
    "    # Obtain min score k\n",
    "    min_k = min(scores, key=lambda x: x[2])[0]\n",
    "    print \"Best k value is %(best_k)d\" % {\"best_k\": min_k}\n",
    "\n",
    "    # Use the best model to assign a cluster to each datum\n",
    "    # We use here standardized data - it is more appropriate for exploratory purposes\n",
    "    print \"Obtaining clustering result sample for k=%(min_k)d...\" % {\"min_k\": min_k}\n",
    "    best_model = min(scores, key=lambda x: x[2])[1]\n",
    "    cluster_assignments_sample = standardized_data_values.map(lambda datum: str(best_model.predict(datum))+\",\"+\",\".join(map(str,datum))).sample(False,0.05)\n",
    "\n",
    "    # Save assignment sample to file\n",
    "    print \"Saving sample to file...\"\n",
    "    cluster_assignments_sample.saveAsTextFile(\"sample_standardized\")\n",
    "    print \"DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-3-d2516bf2dbe3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-d2516bf2dbe3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    dataset = pd.read_csv('C:\\Users\\adiel\\Downloads - kddcup.csv', sep=',')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv('C:\\Users\\adiel\\Downloads - kddcup.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-4-50bb3bec77d8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-50bb3bec77d8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dataset = pd.read_csv('C:\\Users\\adiel\\Downloads kddcup.csv', sep=',')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\Users\\adiel\\Downloads kddcup.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-5-ae434630f5f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-ae434630f5f3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dataset = pd.read_csv('C:\\Users\\adiel\\Downloads\\kddcup.csv', sep=',')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\Users\\adiel\\Downloads\\kddcup.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\scripts\\\\minerandodados\\\\Pandas - Data Science\\\\housesalesprediction\\\\kc_house_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9f6e1a72cab5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\scripts\\minerandodados\\Pandas - Data Science\\housesalesprediction\\kc_house_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\scripts\\\\minerandodados\\\\Pandas - Data Science\\\\housesalesprediction\\\\kc_house_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\scripts\\minerandodados\\Pandas - Data Science\\housesalesprediction\\kc_house_data.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-8-b9661e3df297>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-b9661e3df297>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dataset = pd.read_csv('C:\\Users\\adiel\\Downloads\\iris.csv', sep=',')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\Users\\adiel\\Downloads\\iris.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
